{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# place cell tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Let's say we performed an ephys recording from the hippocampus while an animal ran through a linear track. We want to identify place cells. To do this, we need to get from the raw spiking activity from all neurons to the spatial firing rate maps for spatially modulated cells. \n",
    "\n",
    "![title](images/place_cell_tutorial-02.png)\n",
    "\n",
    "How to we get from the raw data to place cell maps? Let's walk through the steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Before we get started, since we're working in python we need to import the relevant scientific libraries to help us perform our analysis. We're also going to define a few functions that we will use later on, but we don't need to go into the details of here. (Note: to execute a block of code, press the shift + enter keys at the same time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variables and functions that we will use\n",
    "n_positionbins = 50\n",
    "samp_rate = 1000 #Hz\n",
    "\n",
    "def plot_raw_data(df):\n",
    "    '''\n",
    "    This function plots the raw spike trains and mouse trajectories from a given dataframe\n",
    "    '''\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10,4))\n",
    "    fig.suptitle('Raw data')\n",
    "\n",
    "    #plot position data\n",
    "    ax1.plot(df.behavior.position)\n",
    "    ax1.set_ylabel('Position (cm)')\n",
    "    ax1.set_xlabel('Samples')\n",
    "    ax1.set_title('Mouse trajectories')\n",
    "\n",
    "    #plot spike trains\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "    for ineuron in range(np.shape(df.neurons)[1]):\n",
    "        ax2.eventplot(np.where(df.neurons.iloc[:,ineuron])[0],lineoffsets = ineuron, colors = cmap(ineuron))\n",
    "    ax2.set_xlabel('Samples')\n",
    "    ax2.set_ylabel('Neurons')\n",
    "    ax2.set_title('Spike trains');\n",
    "\n",
    "def select_data_when_moving(df,speed_threshold):\n",
    "    '''\n",
    "    This function replaces neuron spike train values with nan if the speed is below a certain threshold\n",
    "    '''\n",
    "    #calc speed\n",
    "    speed = df.behavior.position.diff()*samp_rate #cm/sec\n",
    "    speed[speed<0] = np.nan #replace times when mouse teleported with nan\n",
    "\n",
    "    #replace data points when not moving with nans\n",
    "    mask = speed < speed_threshold\n",
    "    df.loc[mask,\"neurons\"] = np.nan\n",
    "    return df\n",
    "\n",
    "def get_pos_map(df,step,max_pos):\n",
    "    '''\n",
    "    This function gets mapping of samples from data frame to position bin given step size and position of interest\n",
    "    '''\n",
    "    acc_map = np.empty(np.shape(df.behavior.position))\n",
    "    for idx, ibin in enumerate([[i, i+step] for i in range(0, max_pos, step)]): \n",
    "        pos_inds = np.where((df.behavior.position >= min(ibin)) & (df.behavior.position < max(ibin)))[0]\n",
    "        acc_map[pos_inds] = idx\n",
    "    return acc_map\n",
    "        \n",
    "def get_spike_count_map(spike_train,acc_map):\n",
    "    '''\n",
    "    This function bins and sums spike train counts to a given position mapping\n",
    "    '''\n",
    "    st = spike_train.values\n",
    "    keep = ~np.isnan(st)\n",
    "    spike_counts_map = np.bincount(acc_map[keep].astype(int),st[keep])\n",
    "    return spike_counts_map\n",
    "\n",
    "def smooth_with_gaussian(orig_vect,std):\n",
    "    '''\n",
    "    This function smooths a vector using a gaussian window with a given std\n",
    "    '''\n",
    "    #convert data into usable form if is pd.Series\n",
    "    if isinstance(orig_vect,pd.Series):\n",
    "        orig_vect = orig_vect.values\n",
    "\n",
    "    #smooth data\n",
    "    pad_len = np.round(std*2.5)\n",
    "    pad_vect = np.concatenate([np.ones(int(pad_len))*orig_vect[0], orig_vect, np.ones(int(pad_len))*orig_vect[-1]])\n",
    "    gauss_window = signal.gaussian(std*7, std=std)\n",
    "    vect_smooth_long = np.convolve(gauss_window,pad_vect,'same')\n",
    "    vect_smooth = vect_smooth_long[int(pad_len):int(pad_len+len(orig_vect))]\n",
    "    return vect_smooth\n",
    "\n",
    "def plot_rate_maps(rate_map_norm):\n",
    "    '''\n",
    "    This function plots the firing rate maps\n",
    "    '''\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10,4))\n",
    "    fig.suptitle('Firing rate maps')\n",
    "\n",
    "    #heatmap\n",
    "    pos_labels = np.round(np.linspace(0,max_pos,6))\n",
    "    pos_loc = np.round(np.linspace(0,max_pos/2,6))\n",
    "    h = sns.heatmap(rate_map_norm.T,\n",
    "                    xticklabels=pos_labels,\n",
    "                    ax=ax2,\n",
    "                    cbar_kws={'label': 'Firing rate (spikes/s)'},\n",
    "                    vmin=0,\n",
    "                    vmax=1)\n",
    "    h.set_xticks(pos_loc)\n",
    "    h.set_xlabel('Position (cm)')\n",
    "    h.set_ylabel('Neurons')\n",
    "\n",
    "    #line plot \n",
    "    ax1.plot(pos_vect,rate_map_norm)\n",
    "    ax1.set_xlabel('Position (cm)')\n",
    "    ax1.set_ylabel('Firing rate (spikes/s)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 - viewing and cleaning our raw data\n",
    "\n",
    "Let's start with the raw(-ish) data. For each neuron, we have a vector of spike counts for each sample. We also have the time points and positions for the whole recording. First, we will load up the data structure and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('toy_data.pkl') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And when we plot our data, it looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_raw_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to clean our data and make sure we're only using times when the animal is running or moving above a certain speed threshold. When the animals is still, place cells from anywhere in the track are reactivated during sharp-wave ripples and this information can contaminate our place field analysis. To do this, we will replace the data when the animal is below a certain speed threshold with nan values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_threshold = 10 #cm/s\n",
    "df_when_moving = select_data_when_moving(df,speed_threshold)\n",
    "df_when_moving.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 - transforming data in terms of position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get our data put in terms of position and make a *spike counts map*. What this means is that for each neuron, we want to know how many spikes occurred in each position in the track. To do this we will count the number of spikes in each position bin. So if the track is 100m long, we will first count the spikes in the first 1-5m from the start of the track, then  6-10m from the start, then 11-15m, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get map of which samples belong to which position bins for the whole recording\n",
    "max_pos = round(max(df.behavior.position))\n",
    "step = round(max_pos/n_positionbins)\n",
    "pos_vect = np.round(np.linspace(0,max_pos,n_positionbins))\n",
    "accum_map = get_pos_map(df,step,max_pos)\n",
    "\n",
    "#apply mapping to each neuron\n",
    "spike_counts_map = df.neurons.apply(lambda x: get_spike_count_map(x,accum_map))\n",
    "\n",
    "#plot the spatial maps\n",
    "plt.plot(pos_vect,spike_counts_map)\n",
    "plt.xlabel('Position (cm)')\n",
    "plt.ylabel('Spike counts')\n",
    "plt.title('Spatial maps for neurons');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a *spike counts map.* But that won't be enough information to get our place cells, because we also need to know how long the animal spent in each position. If the animal spent a lot of time consuming reward at the end of the track, there will be a LOT of spikes in that location, but that could be due entirely to the time spent in that location. So we now want to get an *occupancy map* to account for time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert code here to get occupancy map\n",
    "time_spent = df.behavior.time.diff()\n",
    "keep = ~np.isnan(time_spent)\n",
    "occupancy_map = np.bincount(accum_map[keep].astype(int),time_spent[keep])\n",
    "\n",
    "#plot the occupancy map\n",
    "plt.plot(pos_vect,occupancy_map)\n",
    "plt.xlabel('Position (cm)')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.title('Occupancy map');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 - generating our spatial maps\n",
    "We now have a spike counts map and an occupancy map. The raw data can be a bit messy across different position bins, so to clean this up and improve our signal to noise ratio, we will smooth the maps. After smoothing the maps, we will combine them in order to get our final spatial map (spike counts normalized by occupancy) for each neuron.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth the maps\n",
    "bin_range = 1\n",
    "spike_counts_map_smooth = spike_counts_map.apply(lambda x: smooth_with_gaussian(x,bin_range))\n",
    "occupancy_map_smooth = smooth_with_gaussian(occupancy_map, bin_range)\n",
    "p = plt.plot(pos_vect,occupancy_map_smooth)\n",
    "plt.xlabel('Position (cm)')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.title('Occupancy map');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make rate maps \n",
    "rate_map = spike_counts_map_smooth.apply(lambda x: x/occupancy_map_smooth)\n",
    "rate_map_norm = rate_map.apply(lambda x: x/max(x))\n",
    "\n",
    "#plot rate maps\n",
    "plot_rate_maps(rate_map_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4 - identifying place cells\n",
    "Now we have a spatial map for every neuron, but that doesn't mean that every neuron is spatially modulated. What we want to do next is identify place cells, neurons that *are* spatially modulated. There are many different ways to do this (spatial info, reliability, firing rate thresholds, etc.), but for the purposes of this tutorial we will a  simple criteria of a peak value that is a certain number of std above the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select place cell data that meets threshold criteria\n",
    "std_threshold = 1.5 #std above the mean firing rate\n",
    "threshold_vals = std_threshold*rate_map_norm.std()+rate_map_norm.mean() \n",
    "place_cell_mask = rate_map_norm.max()>threshold_vals \n",
    "place_cell_maps = rate_map_norm[place_cell_mask.index[place_cell_mask]]\n",
    "\n",
    "#plot final place cells\n",
    "plot_rate_maps(place_cell_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "You now have identified place cells! See the full analysis process we walked through below.\n",
    "\n",
    "![title](images/place_cell_tutorial-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5 - Future directions and other notes\n",
    "You can use these place cells in other analyses, such as place cell reactivation and theta phase precession. You can also look at the spatial map features in more detail and quantify things such as  place fields, peak firing rates, spatial info, etc. \n",
    "\n",
    "For real data, you will need to account for some other things such as empty position bins with zero occupancy or spatial areas with multiple dimensions. The criteria you apply to classify place vs. non-place cells is also important because the output can change depending on which criteria you choose to apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
